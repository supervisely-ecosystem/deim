epoches: 50
batch_size: 16
eval_spatial_size: [640, 640]  # [height, width] Must be divisible by 32

checkpoint_freq: 5  # set 0 to keep only best and last checkpoints
save_optimizer: false
save_ema: false

optimizer:
  type: AdamW
  # lr: 0.0002
  betas: [0.9, 0.999]
  weight_decay: 0.0001

clip_max_norm: 1.0  # gradient clipping

## DEIM LR-Scheduler
lrsheduler: flatcosine
warmup_iter: 200  # first iterations with linear warmup
flat_epoch: 29    # epoches with constant learning rate
no_aug_epoch: 0   # epoches without augmentation

use_ema: False  # Exponential Moving Average for model weights
ema:
  type: ModelEMA
  decay: 0.9999
  warmups: 400

use_amp: True  # Automatic Mixed Precision
